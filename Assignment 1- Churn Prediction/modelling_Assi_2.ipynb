{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03912a28-ab5c-4a4b-8437-f1f25e67a970",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Setup\n",
    "Import modules\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61af76db-b64a-43ac-ac64-5b29df506ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from collections import Counter\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1)\n",
    "tf.random.set_seed(1)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "random_seed = 1\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff3ec40-e820-4d1d-a451-f9fac1da1ac8",
   "metadata": {},
   "source": [
    "## 2. Load data\n",
    "Load data (it's already cleaned and preprocessed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5272b65d-edd2-4b72-aaf9-7611cd98c4e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./ecomm_train_X.csv') \n",
    "y_train = pd.read_csv('./ecomm_train_y.csv') \n",
    "X_test = pd.read_csv('./ecomm_test_X.csv') \n",
    "y_test = pd.read_csv('./ecomm_test_y.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81cccf3b-713e-4333-9943-8e479d35bbe4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3941, 15)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3655237f-6e06-4b0a-9ca1-292eb2f08eb8",
   "metadata": {},
   "source": [
    "### 2.1 Addressing the Imbalance issue  by undersampling technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "741692ea-2621-4898-8c6f-2f32e650bca7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'Churn': 1})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "\n",
    "X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
    "\n",
    "print(Counter(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4043b534-818d-4465-86db-d97c26f060bd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Churn'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383a5e42-637a-48ad-a4a1-c4776e86b4ca",
   "metadata": {},
   "source": [
    "## 3. Model the data\n",
    "First, let's create a dataframe to load the model performance metrics into.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd8b07ed-d2bd-4c14-abd5-5e7e615b39ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "performance = pd.DataFrame({\"model\": [], \"Accuracy\": [], \"Precision\": [], \"Recall\": [], \"F1\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896a79ce-ff8b-435c-bb6a-8a3886642c03",
   "metadata": {},
   "source": [
    "Conduct an initial random search across a wide range of possible parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ef5c54-7bed-444e-9963-42dceb324fb6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.1 Decision Tree \n",
    "### Random Search Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b9508f-634b-40ef-812e-f90529671d29",
   "metadata": {},
   "source": [
    "## Metric Selection = Recall\n",
    "Recall is a commonly used evaluation metric in churn prediction models, and it is often considered to be a more important metric than accuracy or precision for churn detection.\n",
    "\n",
    "Recall, also known as sensitivity or true positive rate, measures the proportion of actual churners that are correctly identified as churners by the model. In other words, it measures the ability of the model to correctly identify all positive cases (i.e., customers who churned) out of the total number of positive cases. In the context of churn prediction, recall can be interpreted as the proportion of customers who are likely to churn that are correctly identified as such by the model. This is particularly important because identifying customers who are at risk of churning is critical for retaining them and minimizing customer churn.\n",
    "\n",
    "In contrast, accuracy measures the proportion of all cases that are correctly identified by the model, regardless of whether they are positive or negative cases. Precision measures the proportion of predicted positive cases that are actually positive, and it is particularly useful in situations where the cost of false positives is high. However, in the context of churn prediction, the cost of false negatives (i.e., failing to identify customers who are likely to churn) is typically higher than the cost of false positives, making recall a more important metric for model evaluation.\n",
    "\n",
    "Overall, while accuracy and precision are important metrics for evaluating the performance of churn prediction models, recall is often considered to be the most important metric for churn detection, as it directly measures the ability of the model to identify customers who are likely to churn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a8bc9fa-7b9b-4449-9224-cdf1ed63e65e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 15 folds for each of 500 candidates, totalling 7500 fits\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 15\n",
    "\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(1, 4000, 10)]\n",
    "min_samples_split = [int(x) for x in np.linspace(2, 5000, 10)]\n",
    "min_samples_leaf = [int(x) for x in np.linspace(1, 10000, 10)]\n",
    "max_leaf_nodes = [int(x) for x in np.linspace(2, len(y_test), 50)]\n",
    "min_impurity_decrease = [x for x in np.arange(0.0, 0.01, 0.0001).round(5)]\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "    'min_samples_split': min_samples_split,  \n",
    "    'min_samples_leaf': min_samples_leaf,\n",
    "    'min_impurity_decrease': min_impurity_decrease,\n",
    "    'max_leaf_nodes': max_leaf_nodes, \n",
    "    'max_depth': max_depth, \n",
    "    'criterion': criterion,\n",
    "}\n",
    "\n",
    "dtree = DecisionTreeClassifier(random_state=random_seed)\n",
    "best_random_search_model = RandomizedSearchCV(estimator = dtree, param_distributions=param_grid, cv=kfolds, n_iter=500,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = best_random_search_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4866581-9f18-4298-8054-1a560abbcdf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'min_samples_split': 2, 'min_samples_leaf': 1, 'min_impurity_decrease': 0.0012, 'max_leaf_nodes': 1585, 'max_depth': 2222, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "random_search_best_params = best_random_search_model.best_params_\n",
    "print('Best parameters found: ', random_search_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0453ebd0-e8c1-46bf-bc06-cf90e77e9cc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 3.2 Decision Tree Grid Search Hyperparameter tunning (Close to Random Search Value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d49d3139-29d5-44aa-8cf5-fddc43d69a7f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1280 candidates, totalling 6400 fits\n",
      "The best recall score is 0.8587285793255942\n",
      "... with parameters: {'criterion': 'gini', 'max_depth': 2218, 'max_leaf_nodes': 1581, 'min_impurity_decrease': 0.0004, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "plus_minus = 4\n",
    "increment = 2\n",
    "\n",
    "param_grid = { 'min_samples_split': [x for x in range(random_search_best_params['min_samples_split']-plus_minus, random_search_best_params['min_samples_split']+plus_minus,2) if x >= 2],       \n",
    "              'min_samples_leaf': [x for x in range(random_search_best_params['min_samples_leaf']-plus_minus , random_search_best_params['min_samples_leaf']+plus_minus,2) if x > 0],\n",
    "              'min_impurity_decrease': [x for x in np.arange(random_search_best_params['min_impurity_decrease']-0.001, random_search_best_params['min_impurity_decrease']+0.001,.0001).round(5) if x >= 0.000],\n",
    "              'max_leaf_nodes':[x for x in range(random_search_best_params['max_leaf_nodes']-plus_minus , random_search_best_params['max_leaf_nodes']+plus_minus, 2) if x > 1],  \n",
    "              'max_depth': [x for x in range(random_search_best_params['max_depth']-plus_minus , random_search_best_params['max_depth']+plus_minus, 2) if x > 1],\n",
    "              'criterion': [random_search_best_params['criterion']]\n",
    "             }\n",
    "\n",
    "dtree = DecisionTreeClassifier(random_state=random_seed)\n",
    "grid_search = GridSearchCV(estimator = dtree, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04a2e604-4843-44ab-af33-6ece98361bf5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_matrix_dt = confusion_matrix(y_test, grid_search.predict(X_test))\n",
    "TP = c_matrix_dt[1][1]\n",
    "TN = c_matrix_dt[0][0]\n",
    "FP = c_matrix_dt[0][1]\n",
    "FN = c_matrix_dt[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Decision Tree Grid_Search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abd63a0-2d5a-4c3a-946d-c5c9ef2d945a",
   "metadata": {},
   "source": [
    "# 4.0 SVM Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd001aaa-5db9-4dfd-8e9a-578aabe1f4c4",
   "metadata": {},
   "source": [
    "### 4.1 SVM Random Search Hyperparameter tunning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5aba2311-c30b-4b40-ac5d-e7b86d868ee8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "# defining parameter range\n",
    "param_grid_svm = {\n",
    "    'C': np.arange(1,25),\n",
    "    'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "    'kernel': ['linear', 'rbf','poly'],\n",
    "} \n",
    "\n",
    "\n",
    "best_random_search_model = RandomizedSearchCV(SVC(), param_distributions=param_grid_svm, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = best_random_search_model.fit(X_train, np.ravel(y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32ecaf6b-707d-4fc8-aea8-656dabd4c287",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'kernel': 'rbf', 'gamma': 0.1, 'C': 9}\n"
     ]
    }
   ],
   "source": [
    "random_search_best_params = best_random_search_model.best_params_\n",
    "print('Best parameters found: ', random_search_best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44198841-f4ea-47fe-8ca8-66070af8f46e",
   "metadata": {},
   "source": [
    "### 4.2 SVM Grid Search Hyperparameter tunning (Close to Randome Search Value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b31b42c-75eb-4895-af99-cb76fee144ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "The best recall score is 0.885428413488115\n",
      "... with parameters: {'C': 7, 'gamma': 0.08, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "# defining parameter range\n",
    "param_grid_svm = {\n",
    "    'C': np.arange(7,11,1),\n",
    "    'gamma': np.arange(0.080,0.12,0.01),\n",
    "    'kernel': ['rbf']\n",
    "} \n",
    "\n",
    "grid_search_svm = GridSearchCV(SVC(), param_grid=param_grid_svm, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search_svm.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search_svm.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search_svm.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "359c8d15-980b-461b-ae72-92f4eee1c6f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_matrix_svm = confusion_matrix(y_test, grid_search_svm.predict(X_test))\n",
    "TP = c_matrix_svm[1][1]\n",
    "TN = c_matrix_svm[0][0]\n",
    "FP = c_matrix_svm[0][1]\n",
    "FN = c_matrix_svm[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"SVM Grid_Search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c269361-e305-43eb-bc0e-d018c95a3977",
   "metadata": {},
   "source": [
    "# 5.0 Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4273672-4230-4f1f-909a-6b593cc29a00",
   "metadata": {},
   "source": [
    "### 5.1 Logistic Regression Random Search Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ac16f36-45f2-4712-b30b-2e1907400b19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "The best recall score is 0.802089552238806\n",
      "... with parameters: {'solver': 'liblinear', 'penalty': 'l1', 'C': 4.281332398719396}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "# defining parameter range\n",
    "param_grid_log = {\n",
    "    'penalty' : ['none', 'l1', 'l2', 'elasticnet'],\n",
    "    'C' : np.logspace(-4, 4, 20),\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear']\n",
    "} \n",
    "\n",
    "random_search_log = RandomizedSearchCV(LogisticRegression(), param_distributions=param_grid_log, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = random_search_log.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "print(f\"The best {score_measure} score is {random_search_log.best_score_}\")\n",
    "print(f\"... with parameters: {random_search_log.best_params_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e26144-ee22-4550-9934-e7b23164d53a",
   "metadata": {},
   "source": [
    "### 5.2 Logistic Regression Grid Search Hyperparameter Tunning (Very Close to Random search Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "202a7fa0-db3d-4d6e-be13-929fec777628",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "The best recall score is 0.802089552238806\n",
      "... with parameters: {'C': 2, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "# defining parameter range\n",
    "param_grid_log = {\n",
    "    'penalty' : ['l1'],\n",
    "    'C' : np.arange(2,7,1),\n",
    "    'solver' : ['liblinear']\n",
    "} \n",
    "\n",
    "grid_search_log = GridSearchCV(LogisticRegression(), param_grid=param_grid_log, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1, \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search_log.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "print(f\"The best {score_measure} score is {grid_search_log.best_score_}\")\n",
    "print(f\"... with parameters: {grid_search_log.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea2baa82-303e-45dc-a4c0-3d9e33a75749",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_matrix_log = confusion_matrix(y_test, grid_search_log.predict(X_test))\n",
    "TP = c_matrix_log[1][1]\n",
    "TN = c_matrix_log[0][0]\n",
    "FP = c_matrix_log[0][1]\n",
    "FN = c_matrix_log[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Logistic Grid_Search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a206b1-398f-441a-8800-372fc969dbfe",
   "metadata": {},
   "source": [
    "# 6.0 Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfa7559a-1481-48a5-a73b-5600d1752714",
   "metadata": {},
   "source": [
    "### 6.1 Neural Network Random Search Hyperparameter Tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8b5e8a9-9dd1-4707-9795-8fe4b0abc29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "{'solver': 'adam', 'max_iter': 5000, 'learning_rate_init': 0.5, 'learning_rate': 'adaptive', 'hidden_layer_sizes': (50, 30), 'alpha': 0, 'activation': 'relu'}\n",
      "CPU times: total: 1.89 s\n",
      "Wall time: 3min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (50,), (70,),(50,30), (40,20), (60,40, 20), (70,50,40)],\n",
    "    'activation': ['logistic', 'tanh', 'relu'],\n",
    "    'solver': ['adam', 'sgd'],\n",
    "    'alpha': [0, .2, .5, .7, 1],\n",
    "    'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "    'learning_rate_init': [0.001, 0.01, 0.1, 0.2, 0.5],\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search_neural = RandomizedSearchCV(estimator = ann, param_distributions=param_grid, cv=kfolds, n_iter=100,\n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search_neural.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search_neural.best_estimator_\n",
    "\n",
    "print(grid_search_neural.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb466e2-f4f4-4aca-a477-c6813667ae08",
   "metadata": {},
   "source": [
    "### 6.2 Neural Network Grid Search Hyperparameter Tunning (Very Close to Random search Values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49e19509-c034-4ab0-aa01-74036546b9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "{'activation': 'relu', 'alpha': 0.6, 'hidden_layer_sizes': (60, 40, 20), 'learning_rate': 'adaptive', 'learning_rate_init': 0.19, 'max_iter': 5000, 'solver': 'sgd'}\n",
      "CPU times: total: 1.09 s\n",
      "Wall time: 57.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "score_measure = \"recall\"\n",
    "kfolds = 5\n",
    "\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [ (60,40, 20)],\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['sgd'],\n",
    "    'alpha': np.arange(0.5,0.9,0.1),\n",
    "    'learning_rate': ['adaptive'],\n",
    "    'learning_rate_init': np.arange(0.18,0.22,0.01),\n",
    "    'max_iter': [5000]\n",
    "}\n",
    "\n",
    "ann = MLPClassifier()\n",
    "grid_search_nn = GridSearchCV(estimator = ann, param_grid=param_grid, cv=kfolds, \n",
    "                           scoring=score_measure, verbose=1, n_jobs=-1,  # n_jobs=-1 will utilize all available CPUs \n",
    "                           return_train_score=True)\n",
    "\n",
    "_ = grid_search_nn.fit(X_train, y_train)\n",
    "\n",
    "bestRecallTree = grid_search_nn.best_estimator_\n",
    "\n",
    "print(grid_search_nn.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "24ac5b27-4506-4fa4-8275-e9469141fd4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_matrix_nn = confusion_matrix(y_test, grid_search_nn.predict(X_test))\n",
    "TP = c_matrix_nn[1][1]\n",
    "TN = c_matrix_nn[0][0]\n",
    "FP = c_matrix_nn[0][1]\n",
    "FN = c_matrix_nn[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Neural Network Grid_Search\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250ef270-5e22-4d6b-972a-345d2f1bc3c2",
   "metadata": {},
   "source": [
    "# 7.0 Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c3a89e-de53-4150-b29a-d3a27396747b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Random Grid earch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97df6aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5e3f5fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define recall metric function\n",
    "def recall(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb11d01a-aef1-44ef-b823-bfc340082dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 20.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# If you don't have the following installed, from command line '!pip install scikeras'\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.initializers import GlorotNormal\n",
    "\n",
    "score_measure = recall\n",
    "kfolds = 5\n",
    "\n",
    "def build_clf(hidden_layer_sizes, dropout): # number of neurons in each hidden layer, while dropout is a float between 0 and 1 that specifies the dropout rate\n",
    "    ann = tf.keras.models.Sequential() #creates a neural network model using the Sequential API in Keras\n",
    "    ann.add(keras.layers.Input(shape=15)), #input layer with a shape of 64\n",
    "    for hidden_layer_size in hidden_layer_sizes: #for loop iterates over each hidden layer size in the list of hidden_layer_sizes and adds a dense layer with that number of neuron\n",
    "        ann.add(keras.layers.Dense(hidden_layer_size, kernel_initializer= tf.keras.initializers.GlorotUniform(),  #initialization method for the weights in the layer\n",
    "                                     bias_initializer=keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None), activation=\"relu\")) #initialization method for the bias terms\n",
    "        ann.add(keras.layers.Dropout(dropout))  ## \n",
    "    ann.add(tf.keras.layers.Dense(1, activation='sigmoid')) #the model has an output layer with 10 neurons, which corresponds to the 10 possible classes in the dataset\n",
    "    ann.compile(loss = 'binary_crossentropy', metrics = recall)\n",
    "    return ann\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42751ed1-318c-42d0-b891-85457d504c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "keras_clf = KerasClassifier(\n",
    "    model=build_clf,\n",
    "    hidden_layer_sizes=15,\n",
    "    dropout = 0.0\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d31bf9c7-0fc1-4e46-a479-ae76ec2d5f70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['model', 'build_fn', 'warm_start', 'random_state', 'optimizer', 'loss', 'metrics', 'batch_size', 'validation_batch_size', 'verbose', 'callbacks', 'validation_split', 'shuffle', 'run_eagerly', 'epochs', 'hidden_layer_sizes', 'dropout', 'class_weight'])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "params = {\n",
    "    'optimizer__learning_rate': [0.0005, 0.001, 0.005],\n",
    "    'model__hidden_layer_sizes': [(70,),(90, ), (100,), (100, 90)],\n",
    "    'model__dropout': [0, 0.1],\n",
    "    'batch_size':[20, 60, 100],\n",
    "    'epochs':[10, 50, 100],\n",
    "    'optimizer':[\"adam\",'sgd']\n",
    "}\n",
    "keras_clf.get_params().keys()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "53e04ffe-74ff-44c6-bd5c-c25fb6a00ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_search_cv = RandomizedSearchCV(estimator=keras_clf, param_distributions=params, scoring=recall, n_iter=50, cv=5)\n",
    "\n",
    "import sys\n",
    "sys.setrecursionlimit(10000) # note: the default is 3000 (python 3.9)\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=5, verbose=0, mode='auto')\n",
    "callback = [earlystop]\n",
    "\n",
    "_ = rnd_search_cv.fit(X_train, y_train, callbacks=callback, verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9704fe92-07cf-4ce1-9170-f28540ea83a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer__learning_rate': 0.001,\n",
       " 'optimizer': 'sgd',\n",
       " 'model__hidden_layer_sizes': (100, 90),\n",
       " 'model__dropout': 0.1,\n",
       " 'epochs': 100,\n",
       " 'batch_size': 60}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2d1225f3-4dd3-488f-9d9c-88de1ce8b914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'optimizer__learning_rate': 0.001, 'optimizer': 'sgd', 'model__hidden_layer_sizes': (100, 90), 'model__dropout': 0.1, 'epochs': 100, 'batch_size': 60}\n"
     ]
    }
   ],
   "source": [
    "best_net = rnd_search_cv.best_estimator_\n",
    "print(rnd_search_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c221c266-4237-4854-83ff-96693c858d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 1ms/step\n",
      "CPU times: total: 46.9 ms\n",
      "Wall time: 234 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_pred = best_net.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e28b2d4-404c-4593-a141-69da4c63cec5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "c_matrix_dnn = confusion_matrix(y_test, y_pred)\n",
    "TP = c_matrix_dnn[1][1]\n",
    "TN = c_matrix_dnn[0][0]\n",
    "FP = c_matrix_dnn[0][1]\n",
    "FN = c_matrix_dnn[1][0]\n",
    "performance = pd.concat([performance, pd.DataFrame({'model':\"Deep Neural Network\", \n",
    "                                                    'Accuracy': [(TP+TN)/(TP+TN+FP+FN)], \n",
    "                                                    'Precision': [TP/(TP+FP)], \n",
    "                                                    'Recall': [TP/(TP+FN)], \n",
    "                                                    'F1': [2*TP/(2*TP+FP+FN)]\n",
    "                                                     }, index=[0])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d77d0f1-93e4-4831-b61a-b17e23b0afd4",
   "metadata": {},
   "source": [
    "## 8.0 Performance Evaluation and Comparison of Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5be56f28-1a7c-4fea-adf6-6aa5cec8a161",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree Grid_Search</td>\n",
       "      <td>0.827709</td>\n",
       "      <td>0.485207</td>\n",
       "      <td>0.891304</td>\n",
       "      <td>0.628352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM Grid_Search</td>\n",
       "      <td>0.839550</td>\n",
       "      <td>0.505071</td>\n",
       "      <td>0.902174</td>\n",
       "      <td>0.647594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Grid_Search</td>\n",
       "      <td>0.769686</td>\n",
       "      <td>0.397086</td>\n",
       "      <td>0.789855</td>\n",
       "      <td>0.528485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Neural Network Grid_Search</td>\n",
       "      <td>0.848431</td>\n",
       "      <td>0.521008</td>\n",
       "      <td>0.898551</td>\n",
       "      <td>0.659574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Deep Neural Network</td>\n",
       "      <td>0.837774</td>\n",
       "      <td>0.502146</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>0.630728</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        model  Accuracy  Precision    Recall        F1\n",
       "0   Decision Tree Grid_Search  0.827709   0.485207  0.891304  0.628352\n",
       "0             SVM Grid_Search  0.839550   0.505071  0.902174  0.647594\n",
       "0        Logistic Grid_Search  0.769686   0.397086  0.789855  0.528485\n",
       "0  Neural Network Grid_Search  0.848431   0.521008  0.898551  0.659574\n",
       "0         Deep Neural Network  0.837774   0.502146  0.847826  0.630728"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1b1e0c-8835-450a-896b-ebfae2a9e360",
   "metadata": {},
   "source": [
    "## 9.0 Confusion Matrix for cost evaluation of best model (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0cc93a7b-3fe7-4d9c-9280-b4a14d2abbac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1169,  244],\n",
       "       [  27,  249]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_matrix_svm  ## Confusion matric of SVM model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a723b919-91f3-472f-b208-e1c1efcec17e",
   "metadata": {},
   "source": [
    "#### 8.1 Discussion of Adding Deep Neural Network classifcation to the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcf7535-393e-4463-a1ad-1f9cfb909677",
   "metadata": {},
   "source": [
    "Even adding Deep Neural network classification to the model above, it produces Recall of 87.68% which is underperformed compared to SVM. Hence to solve our problem statement we will continue with SVM as our best model with recall of 90.21%.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045c2e4c-05af-4fc7-820c-6c82f4f34b69",
   "metadata": {},
   "source": [
    "#### 8.2 Discussion of Confusion Matrix for cost evaluation of best model (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821f605f-00bf-418d-9cc5-51d719c6602f",
   "metadata": {},
   "source": [
    "The confusion matrix for the best model (reveals that there were 249 true positives (TP), 1169 true negatives (TN), 244 false positives (FP), and 27 false negatives (FN). The imbalanced target variable is a possible reason for such values.\n",
    "\n",
    "Let's now examine how this churn detection model can benefit the e-commerce business in financial terms. Let's assume that the business generates an average revenue of USD 100 per month per customer, with an average customer lifetime value of USD 1,000. If the churn detection model can accurately identify an additional 10 customers per month who are at risk of churning, and the business can retain these customers, it would result in an extra monthly revenue of USD 1,000 (USD 100 per customer * 10 customers) and an additional customer lifetime value of USD 10,000 (USD 1,000 per customer * 10 customers) over the lifetime of these customers.\n",
    "\n",
    "However, in our case from the confusion matrix there were 27 false negatives, meaning that the model predicted that these customers would not churn, whereas they actually churned. Based on the example values, the business would lose USD 2,700 per month (USD 100 per customer * 30 customers) and an additional customer lifetime value of USD 27,000 (USD 1,000 per customer * 30 customers) over the lifetime of these customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047f0828-4a92-4a2f-8216-a9580f24983c",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "### Churn detection is a crucial aspect for e-commerce businesses as it can have a significant impact on various factors such as revenue, customer lifetime value, customer satisfaction, and competition. It helps identify customers who are likely to leave, enabling businesses to take proactive measures to retain them and prevent revenue loss. Out of the three evaluated models, the SVM model has the highest recall value of 90.21%, which is the most important metric for churn detection. Besides recall, accuracy is also crucial as it reduces the number of false negatives and focuses on true positive customers. With a recall score of 0.902, the model can correctly identify 90.2% of customers who are likely to churn, indicating its ability to identify a significant proportion of at-risk customers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1849d10-abfc-4d5c-bc4e-f057b210bf88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a63d35-59a5-4277-b0ba-fd09f81b764e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fb4454-cd98-4bc0-b6d0-3cbd574dad01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
